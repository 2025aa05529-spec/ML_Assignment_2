{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0my0HOjZGKaY",
        "outputId": "54e7720b-6dc8-410e-fee9-c036863cc236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['sex' 'cp' 'restecg' 'slope' 'thal']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All models trained and saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [02:35:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ✅ Ensure model directory exists\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/root/heart.csv\")\n",
        "\n",
        "df.replace(\"?\", pd.NA, inplace=True)\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "df[\"target\"] = (df[\"num\"] > 0).astype(int)\n",
        "\n",
        "X = df.drop(columns=[\"id\", \"dataset\", \"num\", \"target\"], errors=\"ignore\")\n",
        "y = df[\"target\"]\n",
        "\n",
        "X = X.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "X_train, _, y_train, _ = train_test_split(\n",
        "    X_imputed, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# ✅ Now these WILL work\n",
        "joblib.dump(imputer, \"model/imputer.pkl\")\n",
        "joblib.dump(scaler, \"model/scaler.pkl\")\n",
        "\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "        use_label_encoder=False\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Train and save models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    joblib.dump(model, f\"model/{name.replace(' ', '_')}.pkl\")\n",
        "\n",
        "print(\"✅ All models trained and saved successfully.\")\n"
      ]
    }
  ]
}